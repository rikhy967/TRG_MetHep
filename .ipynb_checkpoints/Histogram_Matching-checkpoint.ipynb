{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script computes the average histogram of a nifti images dataset and the histogram matching vs the computed average histogram\n",
    "\n",
    "Author: Edda Boccia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified: the original template image is represented here by t_values and t_counts(both computed in the main script)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def hist_match(source, t_values,t_counts):\n",
    "    \"\"\"\n",
    "    Adjust the pixel values of a grayscale image such that its histogram\n",
    "    matches that of a target image\n",
    "\n",
    "    Arguments:\n",
    "    -----------\n",
    "        source: np.ndarray\n",
    "            Image to transform; the histogram is computed over the flattened\n",
    "            array\n",
    "        template: np.ndarray\n",
    "            Template image; can have different dimensions to source\n",
    "    Returns:\n",
    "    -----------\n",
    "        matched: np.ndarray\n",
    "            The transformed output image\n",
    "    \"\"\"\n",
    "\n",
    "    oldshape = source.shape\n",
    "    source = source.ravel()\n",
    "    #template = template.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n",
    "                                            return_counts=True)\n",
    "    print(bin_idx.shape)\n",
    "    print(s_values.shape)\n",
    "    print(s_counts.shape)\n",
    "    #t_values, t_counts = np.unique(template, return_counts=True)\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
    "    t_quantiles /= t_quantiles[-1]\n",
    "\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "\n",
    "    return interp_t_values[bin_idx].reshape(oldshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_orig = \"path_to_N4BiasField/\"  #images path after N4BF correction (each folder represents a patient, folder name = patientID)\n",
    "path_Otsu = \"\"  #path where Otsu masks are stored\n",
    "path_mask = \"\"  #output path \n",
    "patientID=[i.split('_')[0] for i in os.listdir(path_orig) if 'P_N' in i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged = pd.DataFrame()\n",
    "# for cicle aiming at scaling all original images between 0 and 1 before computing their average histogram\n",
    "\n",
    "for folder in patientID:\n",
    "    \n",
    "    Otsu_mask = np.load(path_orig+folder+'_P_OM.npy')       \n",
    "    image = np.load(path_orig+folder+'_P_N4BF.npy')\n",
    "    \n",
    "    image_cropped = image * Otsu_mask\n",
    "    image_T_1=image_cropped[image_cropped >0]     #exclude the background and keep ther body only\n",
    "    image_T_2 = image_T_1.reshape(-1, 1)    #2-dimensional array where each subarray has 1 element\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(image_T_2)\n",
    "    image_T_2_scaled = scaler.transform(image_T_2)\n",
    "\n",
    "    df1 = pd.DataFrame(image_T_2_scaled.ravel())\n",
    "    df_merged = pd.concat([df_merged, df1], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute parameters used for histo matching\n",
    "t_values_path = 'path_to_t/'\n",
    "\n",
    "t_values = np.load(t_values_path + 't_values_HBP.npy') # Code for Hepatobiliary Phase, use PVP for Portal Venous Phase\n",
    "t_counts_norm = np.load('t_counts_norm_HBP.npy')   #t_counts is normalized by the number of FPU patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HISTO MATCHING (for each patient, matching is performed only inside the image body selected via Otsu masks)\n",
    "#before histo matching, each original image is scaled between 0 and 1 (to be consistent with the average histo range)\n",
    "#in MinMaxScaling, min and max are computed inside each original image body and then applied to the whole image\n",
    "\n",
    "for folder in patientID:\n",
    "    \n",
    "    \n",
    "        Otsu_mask = np.load(path_orig+folder+'_HBP_OM.npy')       \n",
    "        image = np.load(path_orig+folder+'_HBP_N4BF.npy')\n",
    "\n",
    "\n",
    "        image_cropped = image * Otsu_mask\n",
    "        image_T_1=image_cropped[image_cropped >0]     #exclude the background and keep the body only\n",
    "        min_value = image_T_1.min()\n",
    "        max_value = image_T_1.max()\n",
    "\n",
    "        image_cropped_01 = (image_cropped - min_value)/ (max_value - min_value)\n",
    "        image_cropped_scaled = image_cropped_01 * Otsu_mask\n",
    "    \n",
    "        #perform histo matching only inside the body and replace the matched region in the original image\n",
    "        loc = np.where(image_cropped_scaled != 0)\n",
    "        pixels = image_cropped_scaled[loc]\n",
    "\n",
    "        new_image = hist_match(pixels,t_values, t_counts_norm)\n",
    "\n",
    "        image_cropped_scaled_matched = image_cropped_scaled.copy()\n",
    "        for i, coord in enumerate(zip(loc[0], loc[1],loc[2])):\n",
    "            image_cropped_scaled_matched[coord[0], coord[1],coord[2]] = new_image[i]\n",
    "        print(\"fine\")\n",
    "\n",
    "        new_image_1=image_cropped_scaled_matched * Otsu_mask\n",
    "        new_image_2 = new_image_1[new_image_1>0]\n",
    "\n",
    "        image_path = os.path.join(path_mask,'Histo_matching_results_MinMaxScaling_noThresh',folder)\n",
    "        \n",
    "        img_np_test = nib.Nifti1Image(image_cropped_scaled_matched, affine=np.eye(4))\n",
    "        nib.save(img_np_test, 'path_to_img_folder/'+folder+'_HBP_matched.nii.gz')\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
